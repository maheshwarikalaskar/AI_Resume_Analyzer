# -*- coding: utf-8 -*-
"""Untitled46.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E_OUpJjVFdaySylYMfQAnAOFYZ0cimnj
"""

import streamlit as st
import pdfplumber
import spacy
from sentence_transformers import SentenceTransformer, util

# Load NLP tools
nlp = spacy.load("en_core_web_sm")
model = SentenceTransformer('all-MiniLM-L6-v2')

st.set_page_config(page_title="AI Resume Analyzer", layout="centered")
st.title("📄 AI Resume Analyzer")
st.write("Analyze your resume and compare it with a job description.")

# --- Functions ---
def extract_text_from_pdf(file):
    with pdfplumber.open(file) as pdf:
        return " ".join(page.extract_text() or "" for page in pdf.pages)

def extract_keywords(text, top_n=25):
    doc = nlp(text)
    keywords = [chunk.text.lower() for chunk in doc.noun_chunks if 1 < len(chunk.text.split()) < 4]
    return list(set(keywords))[:top_n]

def compute_similarity(text1, text2):
    embeddings = model.encode([text1, text2])
    score = util.cos_sim(embeddings[0], embeddings[1])
    return round(score.item() * 100, 2)

# --- UI Inputs ---
resume_file = st.file_uploader("📤 Upload Resume (PDF)", type=["pdf"])
jd_text = st.text_area("📝 Paste the Job Description")

if resume_file and jd_text:
    with st.spinner("Analyzing..."):
        resume_text = extract_text_from_pdf(resume_file)
        resume_keywords = extract_keywords(resume_text)
        jd_keywords = extract_keywords(jd_text)
        score = compute_similarity(resume_text, jd_text)
        missing = list(set(jd_keywords) - set(resume_keywords))

    st.subheader("✅ Match Results")
    st.metric("📊 Match Score", f"{score}%")
    st.write("✅ **Resume Skills Extracted:**", resume_keywords)
    st.write("📌 **JD Skills Extracted:**", jd_keywords)
    st.error(f"❌ **Missing Skills:** {', '.join(missing) if missing else 'None! Great match.'}")